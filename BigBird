import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from transformers import BigBirdTokenizer, TFBigBirdForSequenceClassification
import tensorflow as tf

# Load the data into a Pandas DataFrame
df = pd.read_csv('data.csv')  # Replace 'data.csv' with your actual data file

# Split the data into training and testing sets
train_texts, test_texts, train_labels, test_labels = train_test_split(df['comment'], df['department'], test_size=0.2, random_state=42)

tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')

train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True)

train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels.tolist()
))
test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    test_labels.tolist()
))

model = TFBigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base', num_labels=len(df['department'].unique()))
optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
model.compile(optimizer=optimizer, loss=loss, metrics=[metric])

model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)

_, test_acc = model.evaluate(test_dataset.batch(16))
print('Test accuracy:', test_acc)

def predict_department(comment):
    input_ids = tokenizer.encode(comment, truncation=True, padding=True, max_length=512, return_tensors='tf')
    logits = model.predict(input_ids)[0]
    predicted_class = np.argmax(logits)
    predicted_label = df['department'].unique()[predicted_class]
    return predicted_label

# Example usage:
new_comment = "This is a new comment."
predicted_department = predict_department(new_comment)
print('Predicted department:', predicted_department)







pip install tensorflow tensorflow-text transformers
import tensorflow as tf
import tensorflow_text as text
from transformers import BigBirdTokenizer, TFBigBirdForSequenceClassification
tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')
def prepare_input_data(texts, labels):
    input_ids = []
    attention_masks = []

    for text in texts:
        encoded_text = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=128,
            pad_to_max_length=True,
            truncation=True,
            return_attention_mask=True
        )
        input_ids.append(encoded_text['input_ids'])
        attention_masks.append(encoded_text['attention_mask'])

    return np.array(input_ids), np.array(attention_masks), np.array(labels)

def build_model():
    input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32)
    attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32)
    model = TFBigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base')
    logits = model(input_ids, attention_mask=attention_mask)[0]
    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(logits)

    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)
    return model

# Define model hyperparameters
num_classes = len(df['department_label'].unique())
learning_rate = 1e-5
epsilon = 1e-08
epochs = 5
batch_size = 32

# Build and compile the model
model = build_model()
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Prepare input data
train_texts, train_labels = df_train['comment'].values, df_train['department_label'].values
train_input_ids, train_attention_masks, train_labels = prepare_input_data(train_texts, train_labels)

# Train the model
model.fit(
    [train_input_ids, train_attention_masks],
    train_labels,
    epochs=epochs,
    batch_size=batch_size,
    validation_split=0.2
)

def predict_department(comment):
    input_ids, attention_mask, _ = prepare_input_data([comment], [0])
    prediction = model.predict([input_ids, attention_mask])[0]
    predicted_label = np.argmax(prediction)
    return predicted_label

new_comment = "This is a new comment. What department does it belong to?"
predicted_department = predict_department(new_comment)
