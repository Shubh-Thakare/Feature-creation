{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>top_article</th>\n",
       "      <th>engagement_reaction_count</th>\n",
       "      <th>engagement_comment_count</th>\n",
       "      <th>engagement_share_count</th>\n",
       "      <th>engagement_comment_plugin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Reuters Editorial</td>\n",
       "      <td>NTSB says Autopilot engaged in 2018 California...</td>\n",
       "      <td>The National Transportation Safety Board said ...</td>\n",
       "      <td>https://www.reuters.com/article/us-tesla-crash...</td>\n",
       "      <td>https://s4.reutersmedia.net/resources/r/?m=02&amp;...</td>\n",
       "      <td>2019-09-03T16:22:20Z</td>\n",
       "      <td>WASHINGTON (Reuters) - The National Transporta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the-irish-times</td>\n",
       "      <td>The Irish Times</td>\n",
       "      <td>Eoin Burke-Kennedy</td>\n",
       "      <td>Unemployment falls to post-crash low of 5.2%</td>\n",
       "      <td>Latest monthly figures reflect continued growt...</td>\n",
       "      <td>https://www.irishtimes.com/business/economy/un...</td>\n",
       "      <td>https://www.irishtimes.com/image-creator/?id=1...</td>\n",
       "      <td>2019-09-03T10:32:28Z</td>\n",
       "      <td>The States jobless rate fell to 5.2 per cent l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the-irish-times</td>\n",
       "      <td>The Irish Times</td>\n",
       "      <td>Deirdre McQuillan</td>\n",
       "      <td>Louise Kennedy AW2019: Long coats, sparkling t...</td>\n",
       "      <td>Autumn-winter collection features designer’s g...</td>\n",
       "      <td>https://www.irishtimes.com/\\t\\t\\t\\t\\t\\t\\t/life...</td>\n",
       "      <td>https://www.irishtimes.com/image-creator/?id=1...</td>\n",
       "      <td>2019-09-03T14:40:00Z</td>\n",
       "      <td>Louise Kennedy is showing off her autumn-winte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>North Korean footballer Han joins Italian gian...</td>\n",
       "      <td>Han is the first North Korean player in the Se...</td>\n",
       "      <td>https://www.aljazeera.com/news/2019/09/north-k...</td>\n",
       "      <td>https://www.aljazeera.com/mritems/Images/2019/...</td>\n",
       "      <td>2019-09-03T17:25:39Z</td>\n",
       "      <td>Han Kwang Song, the first North Korean footbal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bbc-news</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>UK government lawyer says proroguing parliamen...</td>\n",
       "      <td>The UK government's lawyer, David Johnston arg...</td>\n",
       "      <td>https://www.bbc.co.uk/news/av/uk-scotland-4956...</td>\n",
       "      <td>https://ichef.bbci.co.uk/news/1024/branded_new...</td>\n",
       "      <td>2019-09-03T14:39:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           source_id         source_name              author  \\\n",
       "0           0             reuters             Reuters   Reuters Editorial   \n",
       "1           1     the-irish-times     The Irish Times  Eoin Burke-Kennedy   \n",
       "2           2     the-irish-times     The Irish Times   Deirdre McQuillan   \n",
       "3           3  al-jazeera-english  Al Jazeera English          Al Jazeera   \n",
       "4           4            bbc-news            BBC News            BBC News   \n",
       "\n",
       "                                               title  \\\n",
       "0  NTSB says Autopilot engaged in 2018 California...   \n",
       "1       Unemployment falls to post-crash low of 5.2%   \n",
       "2  Louise Kennedy AW2019: Long coats, sparkling t...   \n",
       "3  North Korean footballer Han joins Italian gian...   \n",
       "4  UK government lawyer says proroguing parliamen...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The National Transportation Safety Board said ...   \n",
       "1  Latest monthly figures reflect continued growt...   \n",
       "2  Autumn-winter collection features designer’s g...   \n",
       "3  Han is the first North Korean player in the Se...   \n",
       "4  The UK government's lawyer, David Johnston arg...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reuters.com/article/us-tesla-crash...   \n",
       "1  https://www.irishtimes.com/business/economy/un...   \n",
       "2  https://www.irishtimes.com/\\t\\t\\t\\t\\t\\t\\t/life...   \n",
       "3  https://www.aljazeera.com/news/2019/09/north-k...   \n",
       "4  https://www.bbc.co.uk/news/av/uk-scotland-4956...   \n",
       "\n",
       "                                        url_to_image          published_at  \\\n",
       "0  https://s4.reutersmedia.net/resources/r/?m=02&...  2019-09-03T16:22:20Z   \n",
       "1  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T10:32:28Z   \n",
       "2  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T14:40:00Z   \n",
       "3  https://www.aljazeera.com/mritems/Images/2019/...  2019-09-03T17:25:39Z   \n",
       "4  https://ichef.bbci.co.uk/news/1024/branded_new...  2019-09-03T14:39:21Z   \n",
       "\n",
       "                                             content  top_article  \\\n",
       "0  WASHINGTON (Reuters) - The National Transporta...          0.0   \n",
       "1  The States jobless rate fell to 5.2 per cent l...          0.0   \n",
       "2  Louise Kennedy is showing off her autumn-winte...          1.0   \n",
       "3  Han Kwang Song, the first North Korean footbal...          0.0   \n",
       "4                                                NaN          0.0   \n",
       "\n",
       "   engagement_reaction_count  engagement_comment_count  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        6.0                      10.0   \n",
       "2                        NaN                       NaN   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   engagement_share_count  engagement_comment_plugin_count  \n",
       "0                  2528.0                              0.0  \n",
       "1                     2.0                              0.0  \n",
       "2                     NaN                              NaN  \n",
       "3                     7.0                              0.0  \n",
       "4                     0.0                              0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('articles_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7506    consumer spending slows sharply... (third colu...\n",
       "8978    italian bad loan specialists banca ifis and el...\n",
       "3913    get breaking national and world news, broadcas...\n",
       "4586    the move would typically foreshadow an indictm...\n",
       "4126    kevin durant told the wall street journal on t...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']=df['description'].str.lower()\n",
    "df['description'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first click on  then '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example='first click on www.google.com then https://github.com'\n",
    "remove_url(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation\n",
    "\n",
    "# List of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        the national transportation safety board said ...\n",
      "1        latest monthly figures reflect continued growt...\n",
      "2        autumn-winter collection features designer’s g...\n",
      "3        han is the first north korean player in the se...\n",
      "4        the uk government's lawyer, david johnston arg...\n",
      "                               ...                        \n",
      "10432    get breaking national and world news, broadcas...\n",
      "10433    the announcement by julius baer this week that...\n",
      "10434    weston newswanger is just a normal 5-year-old ...\n",
      "10435    a detective is haunted by the case of two wome...\n",
      "10436    who wanted one-time millionaire lanny horwitz ...\n",
      "Name: description, Length: 10437, dtype: object\n",
      "0.21289849281311035\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "df['description']=remove_punct(df['description'])\n",
    "print(df['description'])\n",
    "\n",
    "time1=time.time()-start\n",
    "print(time1)\n",
    "\n",
    "#time1 shows time required to run this command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat word treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('slang.txt','r') as file:\n",
    "    content=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content.replace('\\n',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AFAIK=As Far As I Know,AFK=Away From Keyboard,ASAP=As Soon As Possible,ATK=At The Keyboard,ATM=At The Moment,A3=Anytime Anywhere Anyplace,BAK=Back At Keyboard,BBL=Be Back Later,BBS=Be Back Soon,BFN=Bye For Now,B4N=Bye For Now,BRB=Be Right Back,BRT=Be Right There,BTW=By The Way,B4=Before,B4N=Bye For Now,CU=See You,CUL8R=See You Later,CYA=See You,FAQ=Frequently Asked Questions,FC=Fingers Crossed,FWIW=For What It's Worth,FYI=For Your Information,GAL=Get A Life,GG=Good Game,GN=Good Night,GMTA=Great Minds Think Alike,GR8=Great!,G9=Genius,IC=I See,ICQ=I Seek you (also a chat program),ILU=ILU: I Love You,IMHO=In My Honest/Humble Opinion,IMO=In My Opinion,IOW=In Other Words,IRL=In Real Life,KISS=Keep It Simple Stupid,LDR=Long Distance Relationship,LMAO=Laugh My A.. Off,LOL=Laughing Out Loud,LTNS=Long Time No See,L8R=Later,MTE=My Thoughts Exactly,M8=Mate,NRN=No Reply Necessary,OIC=Oh I See,PITA=Pain In The A..,PRT=Party,PRW=Parents Are Watching,ROFL=Rolling On The Floor Laughing,ROFLOL=Rolling On The Floor Laughing Out Loud,ROTFLMAO=Rolling On The Floor Laughing My A.. Off,SK8=Skate,STATS=Your sex and age,ASL=Age Sex Location,THX=Thank You,TTFN=Ta-Ta For Now!,TTYL=Talk To You Later,U=You,U2=You Too,U4E=Yours For Ever,WB=Welcome Back,WTF=What The F...,WTG=Way To Go!,WUF=Where Are You From?,W8=Wait...,7K=Sick\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "con={}\n",
    "for i in content:\n",
    "    ap=i.split('=')\n",
    "    con[ap[0]]=ap[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime Anywhere Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': \"For What It's Worth\",\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'ILU: I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laugh My A.. Off',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age Sex Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text=[]\n",
    "    for w in text.split():\n",
    "        if w.upper() in con:\n",
    "            new_text.append(con[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Honest/Humble Opinion he is the best'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"IMHO he is the best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, how are you. I hope you are good'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Incorrect_text='hello, howw are you. I hoppe you aree guud'\n",
    "\n",
    "textb=TextBlob(Incorrect_text)\n",
    "textb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "\n",
    "# List of all stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append(\" \")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    \n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']=df['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          national transportation safety board said tu...\n",
       "1        latest monthly figures reflect continued growt...\n",
       "2        autumn-winter collection features designer’s g...\n",
       "3        han     first north korean player     serie   ...\n",
       "4          uk government's lawyer, david johnston argue...\n",
       "                               ...                        \n",
       "10432    get breaking national   world news, broadcast ...\n",
       "10433      announcement   julius baer   week       hire...\n",
       "10434    weston newswanger       normal 5-year-old boy,...\n",
       "10435      detective   haunted     case   two women mis...\n",
       "10436      wanted one-time millionaire lanny horwitz de...\n",
       "Name: description, Length: 10437, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 ='I have Ph.D in A.I'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other techniques for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "5\n",
      "km\n",
      "ride\n",
      "cost\n",
      "is\n",
      "$\n",
      "10.50\n"
     ]
    }
   ],
   "source": [
    "sent2='a 5km ride cost is $10.50'\n",
    "doc2=nlp(sent2)\n",
    "\n",
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "\"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the language\"\n",
    "\n",
    "stemming is fast as compared to lemmitization because sometime the stem word is not part of english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample= 'walk walks walking walked'\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "Lemmatization, unlike stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In lemmatization root word is called **Lemma**. A lemma is the canonical form, dictionary form or citation form of a set of words.\n",
    "\n",
    "In lemmatization, they search each word in wordnet dictionary thats why it is bit slow as compared to stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                Lemma               \n",
      "the                 the                 \n",
      "national            national            \n",
      "transportation      transportation      \n",
      "safety              safety              \n",
      "board               board               \n",
      "said                say                 \n",
      "tuesday             tuesday             \n",
      "a                   a                   \n",
      "tesla               tesla               \n",
      "model               model               \n",
      "s                   s                   \n",
      "was                 be                  \n",
      "in                  in                  \n",
      "autopilot           autopilot           \n",
      "mode                mode                \n",
      "when                when                \n",
      "it                  it                  \n",
      "struck              strike              \n",
      "a                   a                   \n",
      "fire                fire                \n",
      "truck               truck               \n",
      "in                  in                  \n",
      "culver              culver              \n",
      "city                city                \n",
      ",                   ,                   \n",
      "california          california          \n",
      "--                  --                  \n",
      "one                 one                 \n",
      "of                  of                  \n",
      "a                   a                   \n",
      "series              series              \n",
      "of                  of                  \n",
      "crashes             crash               \n",
      "the                 the                 \n",
      "board               board               \n",
      "is                  be                  \n",
      "investigating       investigate         \n",
      "involving           involve             \n",
      "tesla               tesla               \n",
      "'s                  's                  \n",
      "driver              driver              \n",
      "assistance          assistance          \n",
      "system              system              \n",
      ".                   .                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "Wordnet_Lem= WordNetLemmatizer()\n",
    "sentence= df['description'][0]\n",
    "\n",
    "sentence_words= nltk.word_tokenize(sentence)\n",
    "print(\"{0:20}{1:20}\".format(\"word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,Wordnet_Lem.lemmatize(word,pos='v'))) #pos=parts of speech(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation or Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word embedding** :In natural language processing (NLP), word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=cv.fit_transform(df['description'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 71, 'national': 48, 'transportation': 73, 'safety': 60, 'board': 7, 'said': 61, 'tuesday': 75, 'tesla': 68, 'model': 46, 'was': 77, 'in': 34, 'autopilot': 4, 'mode': 45, 'when': 79, 'it': 38, 'struck': 64, 'fire': 25, 'truck': 74, 'culver': 14, 'city': 9, 'california': 8, 'one': 52, 'of': 50, 'series': 63, 'crashes': 13, 'is': 37, 'investigating': 35, 'involving': 36, 'driver': 20, 'assistance': 3, 'system': 65, 'latest': 41, 'monthly': 47, 'figures': 24, 'reflect': 59, 'continued': 11, 'growth': 30, 'headline': 32, 'employment': 22, 'autumn': 5, 'winter': 80, 'collection': 10, 'features': 23, 'designer': 19, 'glittering': 28, 'take': 66, 'on': 51, 'black': 6, 'watch': 78, 'tartan': 67, 'han': 31, 'first': 26, 'north': 49, 'korean': 40, 'player': 54, 'serie': 62, 'and': 0, 'praised': 56, 'during': 21, 'his': 33, 'appearances': 1, 'youth': 82, 'world': 81, 'cups': 15, 'uk': 76, 'government': 29, 'lawyer': 42, 'david': 16, 'johnston': 39, 'argued': 2, 'that': 70, 'proroguing': 57, 'parliament': 53, 'political': 55, 'decision': 18, 'for': 27, 'rather': 58, 'than': 69, 'legal': 43, 'matter': 44, 'court': 12, 'to': 72, 'decide': 17}\n"
     ]
    }
   ],
   "source": [
    "# Number of unique words\n",
    "\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 0 2 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 2 1\n",
      "  1 1 1 0 0 0 0 0 0 1 1 0 1 0 2 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 2 0 0 2\n",
      "  0 1 1 1 0 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "\n",
    "# sparsity: as it contain max zero, it may causes overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-grams\n",
    "\n",
    "able to capture some semantic meaning of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1=CountVectorizer(ngram_range=(2,2))\n",
    "bow=cv1.fit_transform(df['description'][0:5])\n",
    "\n",
    "#(1,1)=unigram  (2,2)=biagram  (3,3)=trigram  (1,2)=unigram+biagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the national': 79, 'national transportation': 52, 'transportation safety': 83, 'safety board': 65, 'board said': 8, 'said tuesday': 66, 'tuesday tesla': 85, 'tesla model': 72, 'model was': 50, 'was in': 87, 'in autopilot': 34, 'autopilot mode': 4, 'mode when': 49, 'when it': 91, 'it struck': 42, 'struck fire': 69, 'fire truck': 24, 'truck in': 84, 'in culver': 35, 'culver city': 15, 'city california': 10, 'california one': 9, 'one of': 57, 'of series': 55, 'series of': 68, 'of crashes': 54, 'crashes the': 14, 'the board': 75, 'board is': 7, 'is investigating': 40, 'investigating involving': 38, 'involving tesla': 39, 'tesla driver': 71, 'driver assistance': 19, 'assistance system': 3, 'latest monthly': 45, 'monthly figures': 51, 'figures reflect': 23, 'reflect continued': 64, 'continued growth': 12, 'growth in': 30, 'in headline': 36, 'headline employment': 32, 'autumn winter': 5, 'winter collection': 92, 'collection features': 11, 'features designer': 22, 'designer glittering': 18, 'glittering take': 27, 'take on': 70, 'on black': 56, 'black watch': 6, 'watch tartan': 90, 'han is': 31, 'is the': 41, 'the first': 77, 'first north': 25, 'north korean': 53, 'korean player': 44, 'player in': 59, 'in the': 37, 'the serie': 80, 'serie and': 67, 'and was': 0, 'was praised': 89, 'praised during': 61, 'during his': 20, 'his appearances': 33, 'appearances during': 1, 'during youth': 21, 'youth world': 94, 'world cups': 93, 'the uk': 81, 'uk government': 86, 'government lawyer': 28, 'lawyer david': 46, 'david johnston': 16, 'johnston argued': 43, 'argued that': 2, 'that proroguing': 74, 'proroguing parliament': 62, 'parliament was': 58, 'was political': 88, 'political decision': 60, 'decision for': 17, 'for the': 26, 'the government': 78, 'government rather': 29, 'rather than': 63, 'than legal': 73, 'legal matter': 47, 'matter for': 48, 'the court': 76, 'court to': 13, 'to decide': 82}\n"
     ]
    }
   ],
   "source": [
    "# Number of biagram words\n",
    "\n",
    "print(cv1.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Tf-Idf\n",
    "\n",
    "Term Frequency= (No of occurance of term ti in document,di) / (Total no of items in the document)\n",
    "\n",
    "Inverse document frequency= loge (Total no of documents in the corpus) / (No. of documents with    term t in them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1507129 , 0.1507129 , 0.30142581, 0.1507129 , 0.1507129 ,\n",
       "        0.        , 0.1507129 , 0.1507129 , 0.1507129 , 0.        ,\n",
       "        0.        , 0.1507129 , 0.        , 0.        , 0.21446694,\n",
       "        0.1507129 , 0.1507129 , 0.1507129 , 0.1507129 , 0.        ,\n",
       "        0.1507129 , 0.1507129 , 0.        , 0.1507129 , 0.30142581,\n",
       "        0.1507129 , 0.        , 0.1507129 , 0.1507129 , 0.1507129 ,\n",
       "        0.1507129 , 0.1507129 , 0.30142581, 0.30142581, 0.1507129 ,\n",
       "        0.1507129 , 0.1507129 , 0.1507129 , 0.1507129 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34287126, 0.        , 0.        , 0.        , 0.34287126,\n",
       "        0.34287126, 0.        , 0.34287126, 0.34287126, 0.24395573,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34287126,\n",
       "        0.        , 0.        , 0.34287126, 0.        , 0.        ,\n",
       "        0.        , 0.34287126, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(df['description'][0:2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.         1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511]\n",
      "['assistance', 'autopilot', 'board', 'california', 'city', 'continued', 'crashes', 'culver', 'driver', 'employment', 'figures', 'fire', 'growth', 'headline', 'in', 'investigating', 'involving', 'is', 'it', 'latest', 'mode', 'model', 'monthly', 'national', 'of', 'one', 'reflect', 'safety', 'said', 'series', 'struck', 'system', 'tesla', 'the', 'transportation', 'truck', 'tuesday', 'was', 'when']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_) # value of idf is constant for all term\n",
    "print(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
