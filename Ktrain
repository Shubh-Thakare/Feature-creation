# Split the data into train and test sets
train_size = int(0.8 * len(df))  # 80% for training, 20% for testing

train_data = df[:train_size]
test_data = df[train_size:]
# Preprocess the text data
(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train_data=train_data,
                                                                   text_column='comments',
                                                                   label_columns='department',
                                                                   val_df=test_data,
                                                                   maxlen=512)

# Create a text classification model
model = text.text_classifier(name='bert', train_data=(x_train, y_train), preproc=preproc)
# Train the model
learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)
learner.fit_onecycle(lr=2e-5, epochs=3)
# Make predictions on new comments
new_comments = ["New comment 1", "New comment 2", ...]  # List of new comments
predictor = ktrain.get_predictor(learner.model, preproc)
predictions = predictor.predict(new_comments)





from sklearn.model_selection import train_test_split

X = df['comments'].values
y = df['department'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
MODEL_NAME = 'bert-base-uncased'
t = text.Transformer(MODEL_NAME, maxlen=500)

train_data = t.preprocess_train(X_train, y_train)
test_data = t.preprocess_test(X_test, y_test)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data, batch_size=6)

learner.fit_onecycle(lr=2e-5, epochs=1)
# Assuming your new comments are stored in a list named 'new_comments'
predictor = ktrain.get_predictor(learner.model, preproc=t)
predictions = predictor.predict(new_comments)
