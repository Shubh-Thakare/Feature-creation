# Split the data into train and test sets
train_size = int(0.8 * len(df))  # 80% for training, 20% for testing

train_data = df[:train_size]
test_data = df[train_size:]
# Preprocess the text data
(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train_data=train_data,
                                                                   text_column='comments',
                                                                   label_columns='department',
                                                                   val_df=test_data,
                                                                   maxlen=512)

# Create a text classification model
model = text.text_classifier(name='bert', train_data=(x_train, y_train), preproc=preproc)
# Train the model
learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)
learner.fit_onecycle(lr=2e-5, epochs=3)
# Make predictions on new comments
new_comments = ["New comment 1", "New comment 2", ...]  # List of new comments
predictor = ktrain.get_predictor(learner.model, preproc)
predictions = predictor.predict(new_comments)





from sklearn.model_selection import train_test_split

X = df['comments'].values
y = df['department'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
MODEL_NAME = 'bert-base-uncased'
t = text.Transformer(MODEL_NAME, maxlen=500)

train_data = t.preprocess_train(X_train, y_train)
test_data = t.preprocess_test(X_test, y_test)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data, batch_size=6)

learner.fit_onecycle(lr=2e-5, epochs=1)
# Assuming your new comments are stored in a list named 'new_comments'
predictor = ktrain.get_predictor(learner.model, preproc=t)
predictions = predictor.predict(new_comments)





(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train_df=df_train,
                                                                   text_column='comments',
                                                                   label_columns='topic',
                                                                   val_df=df_test,
                                                                   maxlen=512,
                                                                   preprocess_mode='bert')






train_size = 0.8  # 80% for training, 20% for validation
train_data = df.sample(frac=train_size, random_state=42)
val_data = df.drop(train_data.index)
MODEL_NAME = 'distilbert-base-uncased'  # Choose the desired transformer model

t = text.Transformer(MODEL_NAME, maxlen=500, class_names=df['topic'].unique())

train_preprocessed = t.preprocess_train(train_data['comment'].values, train_data['topic'].values)
val_preprocessed = t.preprocess_test(val_data['comment'].values, val_data['topic'].values)

model = t.text_classifier('fasttext', train_data=train_preprocessed)

learner = ktrain.get_learner(model, train_data=train_preprocessed, val_data=val_preprocessed, batch_size=6)
learner.fit_onecycle(5e-5, 4)

model_path = 'path_to_save_model'
learner.model.save(model_path)
loaded_model = ktrain.load_predictor(model_path)
new_comments = ['New comment 1', 'New comment 2', 'New comment 3']
predictions = loaded_model.predict(new_comments)





X_train = df['comment'].tolist()
y_train = df['department'].tolist()
model_name = 'bert-base-uncased'
t = text.Transformer(model_name, maxlen=500, classes=list(set(y_train)))
train_data = t.preprocess_train(X_train, y_train)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=train_data)
learner.fit_onecycle(5e-5, 4)

predictor = ktrain.get_predictor(learner.model, preproc=t)
predictor.save('text_classifier')

predictor = ktrain.load_predictor('text_classifier')
new_comment = "This is a new customer comment."
predicted_department = predictor.predict(new_comment)
print(predicted_department)

